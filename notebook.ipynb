{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb9ccd3",
   "metadata": {},
   "source": [
    "# NLP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55db507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.fi import Finnish\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ja import Japanese\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b190ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98542c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fi_core_news_sm\n",
    "!python -m spacy download ja_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f778b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RELATIVE_PATH = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23fb2b",
   "metadata": {},
   "source": [
    "## Q1.1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c97c23",
   "metadata": {},
   "source": [
    "First, lets define the path where the preprocessed data will be stored for later use.\n",
    "We could get issues if storing the data as CSV after tokenization, since the list of tokens:\n",
    "\"['a'], ['b']\", will automatically be converted to a string (since the list contains ',').\n",
    "So let's store it in pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf5bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_set = DATA_RELATIVE_PATH + \"/train_set.pkl\"\n",
    "path_validation_set = DATA_RELATIVE_PATH + \"/validation_set.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffec53a",
   "metadata": {},
   "source": [
    "Let's download the dataset from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f615ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dataset_raw = load_dataset(\"copenlu/answerable_tydiqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b705a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_raw = dataset_raw[\"train\"].to_pandas()\n",
    "validation_set_raw = dataset_raw[\"validation\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95b343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milloin Charles Fort syntyi?</td>\n",
       "      <td>Charles Fort</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
       "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
       "      <td>ダニエル・J・キャラハン</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
       "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?</td>\n",
       "      <td>వేప</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [12], 'answer_text': ['Azadir...</td>\n",
       "      <td>వేప (లాటిన్ Azadirachta indica, syn. Melia aza...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?</td>\n",
       "      <td>চেঙ্গিজ খান</td>\n",
       "      <td>bengali</td>\n",
       "      <td>{'answer_start': [414], 'answer_text': ['বোরজি...</td>\n",
       "      <td>চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...</td>\n",
       "      <td>https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?</td>\n",
       "      <td>రెయ్యలగడ్ద</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [259], 'answer_text': ['27 హె...</td>\n",
       "      <td>రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question_text document_title  language  \\\n",
       "0            Milloin Charles Fort syntyi?   Charles Fort   finnish   \n",
       "1             “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ   ダニエル・J・キャラハン  japanese   \n",
       "2  వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?            వేప    telugu   \n",
       "3      চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?    চেঙ্গিজ খান   bengali   \n",
       "4        రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?     రెయ్యలగడ్ద    telugu   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  {'answer_start': [18], 'answer_text': ['6. elo...   \n",
       "1  {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
       "2  {'answer_start': [12], 'answer_text': ['Azadir...   \n",
       "3  {'answer_start': [414], 'answer_text': ['বোরজি...   \n",
       "4  {'answer_start': [259], 'answer_text': ['27 హె...   \n",
       "\n",
       "                                  document_plaintext  \\\n",
       "0  Charles Hoy Fort (6. elokuuta (joidenkin lähte...   \n",
       "1  “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
       "2  వేప (లాటిన్ Azadirachta indica, syn. Melia aza...   \n",
       "3  চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...   \n",
       "4  రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...   \n",
       "\n",
       "                                        document_url  \n",
       "0       https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
       "1  https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
       "2  https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...  \n",
       "3  https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...  \n",
       "4  https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6510e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preprocessing_summary(df):\n",
    "    num_unanswered = df[df['document_answer_region'] == Annotation_error.UNANSWERED].shape[0]\n",
    "    num_answered_but_failed = df[df['document_answer_region'] == Annotation_error.BAD_TOKENIZATION_OR_DATA].shape[0]\n",
    "    num_answered = df.shape[0] - num_answered_but_failed - num_unanswered\n",
    "\n",
    "    print(\"[Parsing Info] {} answered questions. {} unanswered questions. Failed to parse {} (answered) questions.\".format(num_answered, num_unanswered, num_answered_but_failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eeebef",
   "metadata": {},
   "source": [
    "Let's do some preprocessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce266f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_tokenizer(nlp):\n",
    "    infixes = nlp.Defaults.infixes + [r\"[\\.\\,]?\\[\\S*\"]\n",
    "    infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "    prefix_re = compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "    suffix_re = compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "\n",
    "    return Tokenizer(\n",
    "        nlp.vocab,\n",
    "        prefix_search=prefix_re.search,\n",
    "        suffix_search=suffix_re.search,\n",
    "        infix_finditer=infix_re.finditer,\n",
    "        #token_match=nlp.tokenizer.token_match,\n",
    "        rules=nlp.Defaults.tokenizer_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3260876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_nlp(pipeline_name: str):\n",
    "    nlp = spacy.load(pipeline_name)\n",
    "    nlp.tokenizer = our_tokenizer(nlp)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5311acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation_error(Enum):\n",
    "    UNANSWERED = -1\n",
    "    BAD_TOKENIZATION_OR_DATA = -2\n",
    "    IGNORED = -3\n",
    "\n",
    "def preprocess_annotation(raw_sample, nlp):\n",
    "    document_doc = nlp(raw_sample['document_plaintext'])\n",
    "    annotations = raw_sample['annotations']\n",
    "\n",
    "    # extract answer annotations\n",
    "    start = annotations['answer_start'][0]\n",
    "    if start == -1: # unanswered question\n",
    "        region = Annotation_error.UNANSWERED\n",
    "    else:\n",
    "        length = len(annotations['answer_text'][0])\n",
    "        end = start + length\n",
    "\n",
    "        span = document_doc.char_span(start, end) # or None if the span is within a token\n",
    "\n",
    "        if span == None: # the answer region does not match token boundaries (either due to poor tokenzation or poor data labelling)\n",
    "            region = Annotation_error.BAD_TOKENIZATION_OR_DATA\n",
    "        else:\n",
    "            region = (span.start, span.end)\n",
    "\n",
    "    return region\n",
    "\n",
    "def preprocess_language(raw_df, nlp, preprocess_annotations: bool = True, num_max_rows=-1):\n",
    "    rows = len(raw_df)\n",
    "    \n",
    "    if num_max_rows > 0: # @Remove\n",
    "        rows = min(rows, num_max_rows)\n",
    "    \n",
    "    columns = ['language', 'question', 'document_title', 'document', 'document_answer_region']\n",
    "    df = pd.DataFrame(columns=columns, index=range(rows))\n",
    "    \n",
    "    df['language'] = raw_df['language'].iloc[0]\n",
    " \n",
    "    for i in range(rows):\n",
    "        raw_sample = raw_df.iloc[i]\n",
    "\n",
    "        df.at[i,'question'] = [t.text for t in nlp(raw_sample['question_text'])]\n",
    "        df.at[i,'document_title'] = [t.text for t in nlp(raw_sample['document_title'])]\n",
    "        df.at[i,'document'] = [t.text for t in nlp(raw_sample['document_plaintext'])]\n",
    "        \n",
    "        \n",
    "        if preprocess_annotations:\n",
    "            answer_region = preprocess_annotation(raw_sample, nlp)\n",
    "        else:\n",
    "            answer_region = Annotation_error.IGNORED    \n",
    "        \n",
    "        df.at[i,'document_answer_region'] = answer_region\n",
    "        \n",
    "        \n",
    "        if i % 1000  == 0:\n",
    "            print(\"sample {}/{}\".format(i, rows))\n",
    "            \n",
    "        if i == num_max_rows: # @Remove\n",
    "            break\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d61f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_data, max_rows_per_language=-1):\n",
    "    # @Note: how pipelines work in spacy: https://spacy.io/usage/processing-pipelines\n",
    "    \n",
    "    # english\n",
    "    raw_data_en = raw_data[raw_data['language'] == 'english']\n",
    "    data_en = preprocess_language(raw_data_en, our_nlp('en_core_web_sm'), num_max_rows=max_rows_per_language)\n",
    "    print_preprocessing_summary(data_en)\n",
    "    \n",
    "    # finnish\n",
    "    raw_data_fi = raw_data[raw_data['language'] == 'finnish']\n",
    "    data_fi = preprocess_language(raw_data_fi, our_nlp('fi_core_news_sm'), num_max_rows=max_rows_per_language)\n",
    "    print_preprocessing_summary(data_fi)\n",
    "    \n",
    "    # japanese\n",
    "    # @Note: for some reason, the pretrained pipeline doesn't work well with finding the answer. Japenese() works a lot better. However, maybe it just tokenizes each symbol\n",
    "    raw_data_jp = raw_data[raw_data['language'] == 'japanese']\n",
    "    data_jp = preprocess_language(raw_data_jp, our_nlp('ja_core_news_sm'), num_max_rows=max_rows_per_language) \n",
    "    print_preprocessing_summary(data_jp)\n",
    "    \n",
    "    # concat\n",
    "    data = pd.concat([data_en, data_fi, data_jp])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e541a9",
   "metadata": {},
   "source": [
    "Let's preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f844fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0/7389\n",
      "sample 1000/7389\n",
      "sample 2000/7389\n",
      "sample 3000/7389\n",
      "sample 4000/7389\n",
      "sample 5000/7389\n",
      "sample 6000/7389\n",
      "sample 7000/7389\n",
      "[Parsing Info] 3556 answered questions. 3693 unanswered questions. Failed to parse 140 (answered) questions.\n",
      "sample 0/13701\n",
      "sample 1000/13701\n",
      "sample 2000/13701\n",
      "sample 3000/13701\n",
      "sample 4000/13701\n",
      "sample 5000/13701\n",
      "sample 6000/13701\n",
      "sample 7000/13701\n",
      "sample 8000/13701\n",
      "sample 9000/13701\n",
      "sample 10000/13701\n",
      "sample 11000/13701\n",
      "sample 12000/13701\n",
      "sample 13000/13701\n",
      "[Parsing Info] 6379 answered questions. 6846 unanswered questions. Failed to parse 476 (answered) questions.\n",
      "sample 0/8778\n",
      "sample 1000/8778\n",
      "sample 2000/8778\n",
      "sample 3000/8778\n",
      "sample 4000/8778\n",
      "sample 5000/8778\n",
      "sample 6000/8778\n",
      "sample 7000/8778\n",
      "sample 8000/8778\n",
      "[Parsing Info] 233 answered questions. 4389 unanswered questions. Failed to parse 4156 (answered) questions.\n"
     ]
    }
   ],
   "source": [
    "train_set = preprocess(train_set_raw, max_rows_per_language = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe2754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, was, quantum, field, theory, developed, ?]</td>\n",
       "      <td>[Quantum, field, theory]</td>\n",
       "      <td>[Quantum, field, theory, naturally, began, wit...</td>\n",
       "      <td>(25, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, was, the, first, Nobel, prize, winner, f...</td>\n",
       "      <td>[List, of, Nobel, laureates, in, Literature]</td>\n",
       "      <td>[The, Nobel, Prize, in, Literature, (, Swedish...</td>\n",
       "      <td>(111, 113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, is, the, dialectical, method, used, ?]</td>\n",
       "      <td>[Dialectic]</td>\n",
       "      <td>[Dialectic, or, dialectics, (, Greek, :, διαλε...</td>\n",
       "      <td>(26, 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, invented, Hangul, ?]</td>\n",
       "      <td>[Origin, of, Hangul]</td>\n",
       "      <td>[Hangul, was, personally, created, and, promul...</td>\n",
       "      <td>(15, 18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, do, Grasshoppers, eat, ?]</td>\n",
       "      <td>[Grasshopper]</td>\n",
       "      <td>[Grasshoppers, are, plant, -, eaters, ,, with,...</td>\n",
       "      <td>(0, 37)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  [When, was, quantum, field, theory, developed, ?]   \n",
       "1  english  [Who, was, the, first, Nobel, prize, winner, f...   \n",
       "2  english      [When, is, the, dialectical, method, used, ?]   \n",
       "3  english                         [Who, invented, Hangul, ?]   \n",
       "4  english                   [What, do, Grasshoppers, eat, ?]   \n",
       "\n",
       "                                 document_title  \\\n",
       "0                      [Quantum, field, theory]   \n",
       "1  [List, of, Nobel, laureates, in, Literature]   \n",
       "2                                   [Dialectic]   \n",
       "3                          [Origin, of, Hangul]   \n",
       "4                                 [Grasshopper]   \n",
       "\n",
       "                                            document document_answer_region  \n",
       "0  [Quantum, field, theory, naturally, began, wit...               (25, 26)  \n",
       "1  [The, Nobel, Prize, in, Literature, (, Swedish...             (111, 113)  \n",
       "2  [Dialectic, or, dialectics, (, Greek, :, διαλε...               (26, 49)  \n",
       "3  [Hangul, was, personally, created, and, promul...               (15, 18)  \n",
       "4  [Grasshoppers, are, plant, -, eaters, ,, with,...                (0, 37)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141f857",
   "metadata": {},
   "source": [
    "Let's preprocess the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b40b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0/990\n",
      "[Parsing Info] 482 answered questions. 495 unanswered questions. Failed to parse 13 (answered) questions.\n",
      "sample 0/1686\n",
      "sample 1000/1686\n",
      "[Parsing Info] 771 answered questions. 843 unanswered questions. Failed to parse 72 (answered) questions.\n",
      "sample 0/1036\n",
      "sample 1000/1036\n",
      "[Parsing Info] 24 answered questions. 518 unanswered questions. Failed to parse 494 (answered) questions.\n"
     ]
    }
   ],
   "source": [
    "validation_set = preprocess(validation_set_raw, max_rows_per_language=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e05fb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, is, a, way, to, increase, your, wound, ...</td>\n",
       "      <td>[Wound, healing]</td>\n",
       "      <td>[Wound, care, encourages, and, speeds, wound, ...</td>\n",
       "      <td>(8, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, founded, the, Burntisland, Shipbuilding,...</td>\n",
       "      <td>[Burntisland, Shipbuilding, Company]</td>\n",
       "      <td>[Brothers, Amos, and, Wilfrid, Ayre, founded, ...</td>\n",
       "      <td>(0, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, is, the, surface, area, of, the, human,...</td>\n",
       "      <td>[Cerebral, cortex]</td>\n",
       "      <td>[For, species, of, mammals, ,, larger, brains,...</td>\n",
       "      <td>(61, 63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, did, the, case, of, R, (, Factortame, L...</td>\n",
       "      <td>[R, (, Factortame, Ltd, ), v, Secretary, of, S...</td>\n",
       "      <td>[As, from, 31, March, 1989, ,, fishing, vessel...</td>\n",
       "      <td>(66, 68)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, was, Quezon, City, founded, ?]</td>\n",
       "      <td>[Quezon, City]</td>\n",
       "      <td>[When, Quezon, City, was, created, in, 1939, ,...</td>\n",
       "      <td>(6, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  [What, is, a, way, to, increase, your, wound, ...   \n",
       "1  english  [Who, founded, the, Burntisland, Shipbuilding,...   \n",
       "2  english  [What, is, the, surface, area, of, the, human,...   \n",
       "3  english  [When, did, the, case, of, R, (, Factortame, L...   \n",
       "4  english              [When, was, Quezon, City, founded, ?]   \n",
       "\n",
       "                                      document_title  \\\n",
       "0                                   [Wound, healing]   \n",
       "1               [Burntisland, Shipbuilding, Company]   \n",
       "2                                 [Cerebral, cortex]   \n",
       "3  [R, (, Factortame, Ltd, ), v, Secretary, of, S...   \n",
       "4                                     [Quezon, City]   \n",
       "\n",
       "                                            document document_answer_region  \n",
       "0  [Wound, care, encourages, and, speeds, wound, ...                (8, 15)  \n",
       "1  [Brothers, Amos, and, Wilfrid, Ayre, founded, ...                 (0, 5)  \n",
       "2  [For, species, of, mammals, ,, larger, brains,...               (61, 63)  \n",
       "3  [As, from, 31, March, 1989, ,, fishing, vessel...               (66, 68)  \n",
       "4  [When, Quezon, City, was, created, in, 1939, ,...                 (6, 7)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0e07a",
   "metadata": {},
   "source": [
    "### Save pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25ee3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_pickle(path_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8a223c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set.to_pickle(path_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea561b0",
   "metadata": {},
   "source": [
    "### Load pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59bce828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_set = pd.read_pickle(path_train_set)\n",
    "    validation_set = pd.read_pickle(path_validation_set)\n",
    "    return train_set, validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99db2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92527cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, was, quantum, field, theory, developed, ?]</td>\n",
       "      <td>[Quantum, field, theory]</td>\n",
       "      <td>[Quantum, field, theory, naturally, began, wit...</td>\n",
       "      <td>(25, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, was, the, first, Nobel, prize, winner, f...</td>\n",
       "      <td>[List, of, Nobel, laureates, in, Literature]</td>\n",
       "      <td>[The, Nobel, Prize, in, Literature, (, Swedish...</td>\n",
       "      <td>(111, 113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, is, the, dialectical, method, used, ?]</td>\n",
       "      <td>[Dialectic]</td>\n",
       "      <td>[Dialectic, or, dialectics, (, Greek, :, διαλε...</td>\n",
       "      <td>(26, 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, invented, Hangul, ?]</td>\n",
       "      <td>[Origin, of, Hangul]</td>\n",
       "      <td>[Hangul, was, personally, created, and, promul...</td>\n",
       "      <td>(15, 18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, do, Grasshoppers, eat, ?]</td>\n",
       "      <td>[Grasshopper]</td>\n",
       "      <td>[Grasshoppers, are, plant, -, eaters, ,, with,...</td>\n",
       "      <td>(0, 37)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  [When, was, quantum, field, theory, developed, ?]   \n",
       "1  english  [Who, was, the, first, Nobel, prize, winner, f...   \n",
       "2  english      [When, is, the, dialectical, method, used, ?]   \n",
       "3  english                         [Who, invented, Hangul, ?]   \n",
       "4  english                   [What, do, Grasshoppers, eat, ?]   \n",
       "\n",
       "                                 document_title  \\\n",
       "0                      [Quantum, field, theory]   \n",
       "1  [List, of, Nobel, laureates, in, Literature]   \n",
       "2                                   [Dialectic]   \n",
       "3                          [Origin, of, Hangul]   \n",
       "4                                 [Grasshopper]   \n",
       "\n",
       "                                            document document_answer_region  \n",
       "0  [Quantum, field, theory, naturally, began, wit...               (25, 26)  \n",
       "1  [The, Nobel, Prize, in, Literature, (, Swedish...             (111, 113)  \n",
       "2  [Dialectic, or, dialectics, (, Greek, :, διαλε...               (26, 49)  \n",
       "3  [Hangul, was, personally, created, and, promul...               (15, 18)  \n",
       "4  [Grasshoppers, are, plant, -, eaters, ,, with,...                (0, 37)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a227331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, is, a, way, to, increase, your, wound, ...</td>\n",
       "      <td>[Wound, healing]</td>\n",
       "      <td>[Wound, care, encourages, and, speeds, wound, ...</td>\n",
       "      <td>(8, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, founded, the, Burntisland, Shipbuilding,...</td>\n",
       "      <td>[Burntisland, Shipbuilding, Company]</td>\n",
       "      <td>[Brothers, Amos, and, Wilfrid, Ayre, founded, ...</td>\n",
       "      <td>(0, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, is, the, surface, area, of, the, human,...</td>\n",
       "      <td>[Cerebral, cortex]</td>\n",
       "      <td>[For, species, of, mammals, ,, larger, brains,...</td>\n",
       "      <td>(61, 63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, did, the, case, of, R, (, Factortame, L...</td>\n",
       "      <td>[R, (, Factortame, Ltd, ), v, Secretary, of, S...</td>\n",
       "      <td>[As, from, 31, March, 1989, ,, fishing, vessel...</td>\n",
       "      <td>(66, 68)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, was, Quezon, City, founded, ?]</td>\n",
       "      <td>[Quezon, City]</td>\n",
       "      <td>[When, Quezon, City, was, created, in, 1939, ,...</td>\n",
       "      <td>(6, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  [What, is, a, way, to, increase, your, wound, ...   \n",
       "1  english  [Who, founded, the, Burntisland, Shipbuilding,...   \n",
       "2  english  [What, is, the, surface, area, of, the, human,...   \n",
       "3  english  [When, did, the, case, of, R, (, Factortame, L...   \n",
       "4  english              [When, was, Quezon, City, founded, ?]   \n",
       "\n",
       "                                      document_title  \\\n",
       "0                                   [Wound, healing]   \n",
       "1               [Burntisland, Shipbuilding, Company]   \n",
       "2                                 [Cerebral, cortex]   \n",
       "3  [R, (, Factortame, Ltd, ), v, Secretary, of, S...   \n",
       "4                                     [Quezon, City]   \n",
       "\n",
       "                                            document document_answer_region  \n",
       "0  [Wound, care, encourages, and, speeds, wound, ...                (8, 15)  \n",
       "1  [Brothers, Amos, and, Wilfrid, Ayre, founded, ...                 (0, 5)  \n",
       "2  [For, species, of, mammals, ,, larger, brains,...               (61, 63)  \n",
       "3  [As, from, 31, March, 1989, ,, fishing, vessel...               (66, 68)  \n",
       "4  [When, Quezon, City, was, created, in, 1939, ,...                 (6, 7)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d7d6d",
   "metadata": {},
   "source": [
    "## Q1.1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce55c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_ids(words):\n",
    "    word_to_ix = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "    return word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "620be9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0ae8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['english']\n",
    "\n",
    "for language in languages:\n",
    "    df = train_set[train_set['language'] == language]\n",
    "    \n",
    "    df_question = df['question']\n",
    "    firsts = df_question.map(lambda tokens: tokens[0])\n",
    "    lasts = df_question.map(lambda tokens: tokens[-1])\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(15,6))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ce3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
