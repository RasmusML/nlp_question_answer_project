{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98533c42",
   "metadata": {},
   "source": [
    "# NLP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42dd042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.fi import Finnish\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ja import Japanese\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609de9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135c9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fi_core_news_sm\n",
    "!python -m spacy download ja_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9b79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RELATIVE_PATH = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbff638",
   "metadata": {},
   "source": [
    "## Q1.1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38364dfd",
   "metadata": {},
   "source": [
    "First, lets define the path where the preprocessed data will be stored for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62d822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_set = DATA_RELATIVE_PATH + \"/train_set.csv\"\n",
    "path_validation_set = DATA_RELATIVE_PATH + \"/train_set.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce2135d",
   "metadata": {},
   "source": [
    "Let's download the dataset from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a93b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dataset_raw = load_dataset(\"copenlu/answerable_tydiqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14183c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_raw = dataset_raw[\"train\"].to_pandas()\n",
    "validation_set_raw = dataset_raw[\"validation\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dff8e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milloin Charles Fort syntyi?</td>\n",
       "      <td>Charles Fort</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
       "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
       "      <td>ダニエル・J・キャラハン</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
       "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?</td>\n",
       "      <td>వేప</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [12], 'answer_text': ['Azadir...</td>\n",
       "      <td>వేప (లాటిన్ Azadirachta indica, syn. Melia aza...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?</td>\n",
       "      <td>চেঙ্গিজ খান</td>\n",
       "      <td>bengali</td>\n",
       "      <td>{'answer_start': [414], 'answer_text': ['বোরজি...</td>\n",
       "      <td>চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...</td>\n",
       "      <td>https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?</td>\n",
       "      <td>రెయ్యలగడ్ద</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [259], 'answer_text': ['27 హె...</td>\n",
       "      <td>రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question_text document_title  language  \\\n",
       "0            Milloin Charles Fort syntyi?   Charles Fort   finnish   \n",
       "1             “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ   ダニエル・J・キャラハン  japanese   \n",
       "2  వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?            వేప    telugu   \n",
       "3      চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?    চেঙ্গিজ খান   bengali   \n",
       "4        రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?     రెయ్యలగడ్ద    telugu   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  {'answer_start': [18], 'answer_text': ['6. elo...   \n",
       "1  {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
       "2  {'answer_start': [12], 'answer_text': ['Azadir...   \n",
       "3  {'answer_start': [414], 'answer_text': ['বোরজি...   \n",
       "4  {'answer_start': [259], 'answer_text': ['27 హె...   \n",
       "\n",
       "                                  document_plaintext  \\\n",
       "0  Charles Hoy Fort (6. elokuuta (joidenkin lähte...   \n",
       "1  “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
       "2  వేప (లాటిన్ Azadirachta indica, syn. Melia aza...   \n",
       "3  চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...   \n",
       "4  రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...   \n",
       "\n",
       "                                        document_url  \n",
       "0       https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
       "1  https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
       "2  https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...  \n",
       "3  https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...  \n",
       "4  https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf3eebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preprocessing_summary(df):\n",
    "    num_unanswered = df[df['document_answer_region'] == UNANSWERED].shape[0]\n",
    "    num_answered_but_failed = df[df['document_answer_region'] == BAD_TOKENIZATION_OR_DATA].shape[0]\n",
    "    num_answered = df.shape[0] - num_answered_but_failed - num_unanswered\n",
    "\n",
    "    print(\"[Parsing Info] {} answered questions. {} unanswered questions. Failed to parse {} (answered) questions.\".format(num_answered, num_unanswered, num_answered_but_failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f130b6",
   "metadata": {},
   "source": [
    "Let's do some preprocessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "873dba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_tokenizer(nlp):\n",
    "    infixes = nlp.Defaults.infixes + [r\"[\\.\\,]?\\[\\S*\"]\n",
    "    infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "    prefix_re = compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "    suffix_re = compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "\n",
    "    return Tokenizer(\n",
    "        nlp.vocab,\n",
    "        prefix_search=prefix_re.search,\n",
    "        suffix_search=suffix_re.search,\n",
    "        infix_finditer=infix_re.finditer,\n",
    "        #token_match=nlp.tokenizer.token_match,\n",
    "        rules=nlp.Defaults.tokenizer_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ecab493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_nlp(pipeline_name: str):\n",
    "    nlp = spacy.load(pipeline_name)\n",
    "    nlp.tokenizer = our_tokenizer(nlp)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee330a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation_error(Enum):\n",
    "    UNANSWERED = -1\n",
    "    BAD_TOKENIZATION_OR_DATA = -2\n",
    "    IGNORED = -3\n",
    "\n",
    "def preprocess_annotation(raw_sample, nlp):\n",
    "    document_doc = nlp(raw_sample['document_plaintext'])\n",
    "    annotations = raw_sample['annotations']\n",
    "\n",
    "    # extract answer annotations\n",
    "    start = annotations['answer_start'][0]\n",
    "    if start == -1: # unanswered question\n",
    "        region = UNANSWERED\n",
    "    else:\n",
    "        length = len(annotations['answer_text'][0])\n",
    "        end = start + length\n",
    "\n",
    "        span = document_doc.char_span(start, end) # or None if the span is within a token\n",
    "\n",
    "        if span == None: # the answer region does not match token boundaries (either due to poor tokenzation or poor data labelling)\n",
    "            region = BAD_TOKENIZATION_OR_DATA\n",
    "        else:\n",
    "            region = (span.start, span.end)\n",
    "\n",
    "    return region\n",
    "\n",
    "def preprocess_language(raw_df, nlp, preprocess_annotations: bool = False, num_max_rows=-1):\n",
    "    rows = len(raw_df)\n",
    "    \n",
    "    if num_max_rows > 0: # @Remove\n",
    "        rows = min(rows, num_max_rows)\n",
    "    \n",
    "    columns = ['language', 'question', 'document_title', 'document', 'document_answer_region']\n",
    "    df = pd.DataFrame(columns=columns, index=range(rows))\n",
    "    \n",
    "    df['language'] = raw_df['language'].iloc[0]\n",
    " \n",
    "    for i in range(rows):\n",
    "        raw_sample = raw_df.iloc[i]\n",
    "\n",
    "        df.at[i,'question'] = [t.text for t in nlp(raw_sample['question_text'])]\n",
    "        df.at[i,'document_title'] = [t.text for t in nlp(raw_sample['document_title'])]\n",
    "        df.at[i,'document'] = [t.text for t in nlp(raw_sample['document_plaintext'])]\n",
    "        \n",
    "        \n",
    "        if preprocess_annotations:\n",
    "            answer_region = preprocess_annotation(raw_sample, nlp)\n",
    "        else:\n",
    "            answer_region = IGNORED    \n",
    "        \n",
    "        df.at[i,'document_answer_region'] = answer_region\n",
    "        \n",
    "        \n",
    "        if i % 1000  == 0:\n",
    "            print(\"sample {}/{}\".format(i, rows))\n",
    "            \n",
    "        if i == num_max_rows: # @Remove\n",
    "            break\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "510f228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_data, max_rows_per_language=-1):\n",
    "    # english\n",
    "    raw_data_en = raw_data[raw_data['language'] == 'english']\n",
    "    data_en = preprocess_language(raw_data_en, our_nlp('en_core_web_sm'), num_max_rows=max_rows_per_language)\n",
    "    print_preprocessing_summary(data_en)\n",
    "    \n",
    "    # finnish\n",
    "    raw_data_fi = raw_data[raw_data['language'] == 'finnish']\n",
    "    data_fi = preprocess_language(raw_data_fi, our_nlp('fi_core_news_sm'), num_max_rows=max_rows_per_language)\n",
    "    print_preprocessing_summary(data_fi)\n",
    "    \n",
    "    # japanese\n",
    "    # @Note: for some reason, the pretrained pipeline doesn't work well with finding the answer. Japenese() works a lot better. However, maybe it just tokenizes each symbol\n",
    "    raw_data_jp = raw_data[raw_data['language'] == 'japanese']\n",
    "    data_jp = preprocess_language(raw_data_jp, our_nlp('ja_core_news_sm'), num_max_rows=max_rows_per_language) \n",
    "    print_preprocessing_summary(data_jp)\n",
    "    \n",
    "    # concat\n",
    "    data = pd.concat([data_en, data_fi, data_jp])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9b6a1",
   "metadata": {},
   "source": [
    "Let's preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "79e6f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0/100\n",
      "[Parsing Info] 100 answered questions. 0 unanswered questions. Failed to parse 0 (answered) questions.\n",
      "sample 0/100\n",
      "[Parsing Info] 100 answered questions. 0 unanswered questions. Failed to parse 0 (answered) questions.\n",
      "sample 0/100\n",
      "[Parsing Info] 100 answered questions. 0 unanswered questions. Failed to parse 0 (answered) questions.\n"
     ]
    }
   ],
   "source": [
    "train_set = preprocess(train_set_raw, max_rows_per_language = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5f4f9310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, was, quantum, field, theory, developed, ?]</td>\n",
       "      <td>[Quantum, field, theory]</td>\n",
       "      <td>[Quantum, field, theory, naturally, began, wit...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, was, the, first, Nobel, prize, winner, f...</td>\n",
       "      <td>[List, of, Nobel, laureates, in, Literature]</td>\n",
       "      <td>[The, Nobel, Prize, in, Literature, (, Swedish...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, is, the, dialectical, method, used, ?]</td>\n",
       "      <td>[Dialectic]</td>\n",
       "      <td>[Dialectic, or, dialectics, (, Greek, :, διαλε...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, invented, Hangul, ?]</td>\n",
       "      <td>[Origin, of, Hangul]</td>\n",
       "      <td>[Hangul, was, personally, created, and, promul...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, do, Grasshoppers, eat, ?]</td>\n",
       "      <td>[Grasshopper]</td>\n",
       "      <td>[Grasshoppers, are, plant, -, eaters, ,, with,...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  [When, was, quantum, field, theory, developed, ?]   \n",
       "1  english  [Who, was, the, first, Nobel, prize, winner, f...   \n",
       "2  english      [When, is, the, dialectical, method, used, ?]   \n",
       "3  english                         [Who, invented, Hangul, ?]   \n",
       "4  english                   [What, do, Grasshoppers, eat, ?]   \n",
       "\n",
       "                                 document_title  \\\n",
       "0                      [Quantum, field, theory]   \n",
       "1  [List, of, Nobel, laureates, in, Literature]   \n",
       "2                                   [Dialectic]   \n",
       "3                          [Origin, of, Hangul]   \n",
       "4                                 [Grasshopper]   \n",
       "\n",
       "                                            document document_answer_region  \n",
       "0  [Quantum, field, theory, naturally, began, wit...                     -3  \n",
       "1  [The, Nobel, Prize, in, Literature, (, Swedish...                     -3  \n",
       "2  [Dialectic, or, dialectics, (, Greek, :, διαλε...                     -3  \n",
       "3  [Hangul, was, personally, created, and, promul...                     -3  \n",
       "4  [Grasshoppers, are, plant, -, eaters, ,, with,...                     -3  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dbee9e",
   "metadata": {},
   "source": [
    "Let's preprocess the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cb8df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0/100\n",
      "[Parsing Info] 100 answered questions. 0 unanswered questions. Failed to parse 0 (answered) questions.\n",
      "sample 0/100\n",
      "[Parsing Info] 100 answered questions. 0 unanswered questions. Failed to parse 0 (answered) questions.\n",
      "sample 0/100\n",
      "[Parsing Info] 100 answered questions. 0 unanswered questions. Failed to parse 0 (answered) questions.\n"
     ]
    }
   ],
   "source": [
    "validation_set = preprocess(validation_set_raw, max_rows_per_language = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "329a084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, is, a, way, to, increase, your, wound, ...</td>\n",
       "      <td>[Wound, healing]</td>\n",
       "      <td>[Wound, care, encourages, and, speeds, wound, ...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>[Who, founded, the, Burntisland, Shipbuilding,...</td>\n",
       "      <td>[Burntisland, Shipbuilding, Company]</td>\n",
       "      <td>[Brothers, Amos, and, Wilfrid, Ayre, founded, ...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>[What, is, the, surface, area, of, the, human,...</td>\n",
       "      <td>[Cerebral, cortex]</td>\n",
       "      <td>[For, species, of, mammals, ,, larger, brains,...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, did, the, case, of, R, (, Factortame, L...</td>\n",
       "      <td>[R, (, Factortame, Ltd, ), v, Secretary, of, S...</td>\n",
       "      <td>[As, from, 31, March, 1989, ,, fishing, vessel...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>[When, was, Quezon, City, founded, ?]</td>\n",
       "      <td>[Quezon, City]</td>\n",
       "      <td>[When, Quezon, City, was, created, in, 1939, ,...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  [What, is, a, way, to, increase, your, wound, ...   \n",
       "1  english  [Who, founded, the, Burntisland, Shipbuilding,...   \n",
       "2  english  [What, is, the, surface, area, of, the, human,...   \n",
       "3  english  [When, did, the, case, of, R, (, Factortame, L...   \n",
       "4  english              [When, was, Quezon, City, founded, ?]   \n",
       "\n",
       "                                      document_title  \\\n",
       "0                                   [Wound, healing]   \n",
       "1               [Burntisland, Shipbuilding, Company]   \n",
       "2                                 [Cerebral, cortex]   \n",
       "3  [R, (, Factortame, Ltd, ), v, Secretary, of, S...   \n",
       "4                                     [Quezon, City]   \n",
       "\n",
       "                                            document document_answer_region  \n",
       "0  [Wound, care, encourages, and, speeds, wound, ...                     -3  \n",
       "1  [Brothers, Amos, and, Wilfrid, Ayre, founded, ...                     -3  \n",
       "2  [For, species, of, mammals, ,, larger, brains,...                     -3  \n",
       "3  [As, from, 31, March, 1989, ,, fishing, vessel...                     -3  \n",
       "4  [When, Quezon, City, was, created, in, 1939, ,...                     -3  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b26f8",
   "metadata": {},
   "source": [
    "### Save pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b371d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(path_train_set, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4ddc711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set.to_csv(path_validation_set, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bfafe5",
   "metadata": {},
   "source": [
    "### Load pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5301d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2 = pd.read_csv(path_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea1923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>['When', 'was', 'quantum', 'field', 'theory', ...</td>\n",
       "      <td>['Quantum', 'field', 'theory', 'naturally', 'b...</td>\n",
       "      <td>(25, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>['Who', 'was', 'the', 'first', 'Nobel', 'prize...</td>\n",
       "      <td>['The', 'Nobel', 'Prize', 'in', 'Literature', ...</td>\n",
       "      <td>(111, 113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>['When', 'is', 'the', 'dialectical', 'method',...</td>\n",
       "      <td>['Dialectic', 'or', 'dialectics', '(', 'Greek'...</td>\n",
       "      <td>(26, 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>['Who', 'invented', 'Hangul', '?']</td>\n",
       "      <td>['Hangul', 'was', 'personally', 'created', 'an...</td>\n",
       "      <td>(15, 18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>['What', 'do', 'Grasshoppers', 'eat', '?']</td>\n",
       "      <td>['Grasshoppers', 'are', 'plant', '-', 'eaters'...</td>\n",
       "      <td>(0, 37)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  ['When', 'was', 'quantum', 'field', 'theory', ...   \n",
       "1  english  ['Who', 'was', 'the', 'first', 'Nobel', 'prize...   \n",
       "2  english  ['When', 'is', 'the', 'dialectical', 'method',...   \n",
       "3  english                 ['Who', 'invented', 'Hangul', '?']   \n",
       "4  english         ['What', 'do', 'Grasshoppers', 'eat', '?']   \n",
       "\n",
       "                                              answer answer_region  \n",
       "0  ['Quantum', 'field', 'theory', 'naturally', 'b...      (25, 26)  \n",
       "1  ['The', 'Nobel', 'Prize', 'in', 'Literature', ...    (111, 113)  \n",
       "2  ['Dialectic', 'or', 'dialectics', '(', 'Greek'...      (26, 49)  \n",
       "3  ['Hangul', 'was', 'personally', 'created', 'an...      (15, 18)  \n",
       "4  ['Grasshoppers', 'are', 'plant', '-', 'eaters'...       (0, 37)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e290a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set2 = pd.read_csv(path_validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "46a1f4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>question</th>\n",
       "      <th>document_title</th>\n",
       "      <th>document</th>\n",
       "      <th>document_answer_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>['What', 'is', 'a', 'way', 'to', 'increase', '...</td>\n",
       "      <td>['Wound', 'healing']</td>\n",
       "      <td>['Wound', 'care', 'encourages', 'and', 'speeds...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>['Who', 'founded', 'the', 'Burntisland', 'Ship...</td>\n",
       "      <td>['Burntisland', 'Shipbuilding', 'Company']</td>\n",
       "      <td>['Brothers', 'Amos', 'and', 'Wilfrid', 'Ayre',...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>['What', 'is', 'the', 'surface', 'area', 'of',...</td>\n",
       "      <td>['Cerebral', 'cortex']</td>\n",
       "      <td>['For', 'species', 'of', 'mammals', ',', 'larg...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>['When', 'did', 'the', 'case', 'of', 'R', '(',...</td>\n",
       "      <td>['R', '(', 'Factortame', 'Ltd', ')', 'v', 'Sec...</td>\n",
       "      <td>['As', 'from', '31', 'March', '1989', ',', 'fi...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>['When', 'was', 'Quezon', 'City', 'founded', '?']</td>\n",
       "      <td>['Quezon', 'City']</td>\n",
       "      <td>['When', 'Quezon', 'City', 'was', 'created', '...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           question  \\\n",
       "0  english  ['What', 'is', 'a', 'way', 'to', 'increase', '...   \n",
       "1  english  ['Who', 'founded', 'the', 'Burntisland', 'Ship...   \n",
       "2  english  ['What', 'is', 'the', 'surface', 'area', 'of',...   \n",
       "3  english  ['When', 'did', 'the', 'case', 'of', 'R', '(',...   \n",
       "4  english  ['When', 'was', 'Quezon', 'City', 'founded', '?']   \n",
       "\n",
       "                                      document_title  \\\n",
       "0                               ['Wound', 'healing']   \n",
       "1         ['Burntisland', 'Shipbuilding', 'Company']   \n",
       "2                             ['Cerebral', 'cortex']   \n",
       "3  ['R', '(', 'Factortame', 'Ltd', ')', 'v', 'Sec...   \n",
       "4                                 ['Quezon', 'City']   \n",
       "\n",
       "                                            document  document_answer_region  \n",
       "0  ['Wound', 'care', 'encourages', 'and', 'speeds...                      -3  \n",
       "1  ['Brothers', 'Amos', 'and', 'Wilfrid', 'Ayre',...                      -3  \n",
       "2  ['For', 'species', 'of', 'mammals', ',', 'larg...                      -3  \n",
       "3  ['As', 'from', '31', 'March', '1989', ',', 'fi...                      -3  \n",
       "4  ['When', 'Quezon', 'City', 'was', 'created', '...                      -3  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbf12f",
   "metadata": {},
   "source": [
    "## Q1.1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175a8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
